{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sydney Part Time Data Science Course\n",
    "## Lesson 17 - Artificial Neural Networks Lab\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab is shamelessly taken from the first part of the link below, with only minor adaptations:\n",
    "\n",
    "https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/\n",
    "\n",
    "**NOTE - We have been using Python for over 2months now!**\n",
    "\n",
    "**--> Want to see examples of individuals using the '?' function to find out what a function/object actually does / is.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sungw'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import getpass\n",
    "mymusername = getpass.getuser()\n",
    "mymusername"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/sungw/Repos/dat11syd/data/mnist.npz'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Absolute path to dataset must be defined in this case:\n",
    "mnist_path = \"C:/Users/sungw/Repos/dat11syd/data/mnist.npz\"\n",
    "mnist_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data(path=mnist_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAD8CAYAAADub8g7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26071445d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot 4 images as gray scale\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training dataset is structured as a 3-dimensional array of instance, image width and image height. For a multi-layer perceptron model we must reduce the images down into a vector of pixels. In this case the 28×28 sized images will be 784 pixel input values.\n",
    "\n",
    "We can do this transform easily using the reshape() function on the NumPy array. We can also reduce our memory requirements by forcing the precision of the pixel values to be 32 bit, the default precision used by Keras anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten 28*28 images to a 784 vector for each image\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixel values are gray scale between 0 and 255. It is almost always a good idea to perform some scaling of input values when using neural network models. Because the scale is well known and well behaved, we can very quickly normalize the pixel values to the range 0 and 1 by dividing each value by the maximum of 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the output variable is an integer from 0 to 9. This is a multi-class classification problem. As such, it is good practice to use a one hot encoding of the class values, transforming the vector of class integers into a binary matrix.\n",
    "\n",
    "We can easily do this using the built-in np_utils.to_categorical() helper function in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is a simple neural network with one hidden layer with the same number of neurons as there are inputs (784). A rectifier activation function is used for the neurons in the hidden layer.\n",
    "\n",
    "A softmax activation function is used on the output layer to turn the outputs into probability-like values and allow one class of the 10 to be selected as the model’s output prediction. Logarithmic loss is used as the loss function (called categorical_crossentropy in Keras) and the efficient ADAM gradient descent algorithm is used to learn the weights.\n",
    "\n",
    "We can now fit and evaluate the model. The model is fit over 10 epochs with updates every 200 images. The test data is used as the validation dataset, allowing you to see the skill of the model as it trains. A verbose value of 2 is used to reduce the output to one line for each training epoch.\n",
    "\n",
    "Finally, the test dataset is used to evaluate the model and a classification error rate is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 9s - loss: 0.2783 - acc: 0.9209 - val_loss: 0.1418 - val_acc: 0.9573\n",
      "Epoch 2/10\n",
      " - 8s - loss: 0.1118 - acc: 0.9677 - val_loss: 0.0926 - val_acc: 0.9706\n",
      "Epoch 3/10\n",
      " - 8s - loss: 0.0721 - acc: 0.9795 - val_loss: 0.0781 - val_acc: 0.9773\n",
      "Epoch 4/10\n",
      " - 8s - loss: 0.0503 - acc: 0.9857 - val_loss: 0.0739 - val_acc: 0.9766\n",
      "Epoch 5/10\n",
      " - 8s - loss: 0.0373 - acc: 0.9892 - val_loss: 0.0669 - val_acc: 0.9796\n",
      "Epoch 6/10\n",
      " - 9s - loss: 0.0268 - acc: 0.9926 - val_loss: 0.0625 - val_acc: 0.9805\n",
      "Epoch 7/10\n",
      " - 10s - loss: 0.0209 - acc: 0.9948 - val_loss: 0.0610 - val_acc: 0.9819\n",
      "Epoch 8/10\n",
      " - 9s - loss: 0.0139 - acc: 0.9969 - val_loss: 0.0636 - val_acc: 0.9802\n",
      "Epoch 9/10\n",
      " - 9s - loss: 0.0105 - acc: 0.9979 - val_loss: 0.0571 - val_acc: 0.9819\n",
      "Epoch 10/10\n",
      " - 9s - loss: 0.0076 - acc: 0.9987 - val_loss: 0.0579 - val_acc: 0.9819\n",
      "Baseline Error: 1.81%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
